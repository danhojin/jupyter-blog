{
  
    
        "post0": {
            "title": "안녕! Tensorflow Probability - 3",
            "content": "import numpy as np import pandas as pd import seaborn as sns import matplotlib.pyplot as plt %matplotlib inline import tensorflow as tf from tensorflow.keras import models, layers import tensorflow_probability as tfp tfd = tfp.distributions if tf.test.gpu_device_name() != &#39;/device:GPU:0&#39;: print(&#39;WARNING: GPU device not found.&#39;) else: print(&#39;SUCCESS: Found GPU: {}&#39;.format(tf.test.gpu_device_name())) . SUCCESS: Found GPU: /device:GPU:0 . &#45936;&#51060;&#53552; . 가상의 데이터에 대하여 회귀 문제를 구성해 보자. 다음 코드는 확률젹 회귀 튜토리얼에서 따온 것이다. 이전 포스트에 이어 분석을 진행해 보겠다. . w0 = 0.125 b0 = 5. x_range = [-20, 60] def load_dataset(n=150, n_tst=150): np.random.seed(43) def s(x): g = (x - x_range[0]) / (x_range[1] - x_range[0]) return 3 * (0.25 + g**2.) x = (x_range[1] - x_range[0]) * np.random.rand(n) + x_range[0] eps = np.random.randn(n) * s(x) y0 = (w0 * x * (1. + np.sin(x)) + b0) y = y0 + eps x = x[..., np.newaxis] x_tst = np.linspace(*x_range, num=n_tst).astype(np.float32) x_tst = x_tst[..., np.newaxis] return y0, y, x, x_tst y0, y, x, x_tst = load_dataset() . ax = sns.lineplot(x=x.squeeze(), y=y0) ax = sns.scatterplot(x=x.squeeze(), y=y, color=sns.color_palette()[1]) ax.set_aspect(&#39;equal&#39;); . &#47784;&#45944;6 . 관측 데이터는 이분산성을 보인다. 변동에 대한 표준 편차도 선형으로 변한다고 생각하고 모델을 세우고 싶다. 이를 위하여 Dense 층을 추가하여 하나는 평균에 하나는 표준 편차에 부가하여 확률 변수를 얻겠다. . mod_6 = models.Sequential([ layers.Input(1), layers.Dense(2), tfp.layers.DistributionLambda( lambda t: tfd.Normal( loc=t[..., :1], scale=tf.math.pow(1e-3 + tf.math.softplus(0.01 * t[..., 1:]), 2.0)) ) ]) mod_6.summary() . Model: &#34;sequential&#34; _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= dense (Dense) (None, 2) 4 _________________________________________________________________ distribution_lambda (Distrib multiple 0 ================================================================= Total params: 4 Trainable params: 4 Non-trainable params: 0 _________________________________________________________________ . epochs = 5000 negloglik = lambda y, rv_y: -rv_y.log_prob(y) mod_6.compile(optimizer=tf.optimizers.Adam(learning_rate=0.01), loss=negloglik) history = mod_6.fit(x, y, epochs=epochs, verbose=False) . [print(np.squeeze(w.numpy())) for w in mod_6.weights]; . [0.12824 2.0271993] [ 5.1934476 98.73518 ] . df = history.history df[&#39;epoch&#39;] = list(range(epochs)) df = pd.DataFrame(df) ax = sns.lineplot(data=df, x=&#39;epoch&#39;, y=&#39;loss&#39;) ax.set_yscale(&#39;log&#39;); . fig, ax = plt.subplots(figsize=(10, 5)) ax = sns.scatterplot(x=x.squeeze(), y=y, color=&#39;orange&#39;, label=&#39;observed&#39;) rv_yhat = mod_6(x_tst) ax = sns.scatterplot(x=x_tst.squeeze(), y=rv_yhat.sample().numpy().squeeze(), color=&#39;b&#39;, label=&#39;sample&#39;) ax.set_aspect(&#39;equal&#39;) ax.legend(); . 모델6에서 얻은 표본은 관측 데이터와 비슷한 경향의 분포를 보인다. 또한 앙상블을 통하여 추론도 가능한 모델을 얻었다. . Tensorflow probability는 keras에 확률 프로그래밍을 매끄럽게 넣었다는 느낌을 받았다. 향후 포스트에서는 이 도구로 어떤 것을 수행할 수 있는지 정리해 보겠다. .",
            "url": "https://danhojin.github.io/jupyter-blog/ppl/2021/01/17/hello-tfp3.html",
            "relUrl": "/ppl/2021/01/17/hello-tfp3.html",
            "date": " • Jan 17, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "안녕! Tensorflow Probability - 2",
            "content": "import numpy as np import pandas as pd import seaborn as sns import matplotlib.pyplot as plt %matplotlib inline import tensorflow as tf from tensorflow.keras import models, layers import tensorflow_probability as tfp tfd = tfp.distributions if tf.test.gpu_device_name() != &#39;/device:GPU:0&#39;: print(&#39;WARNING: GPU device not found.&#39;) else: print(&#39;SUCCESS: Found GPU: {}&#39;.format(tf.test.gpu_device_name())) . SUCCESS: Found GPU: /device:GPU:0 . &#48176;&#52824;&#50752; &#51060;&#48292;&#53944; . 확률 프로그래밍 언어인 pyro나 tfp에서 batch_size와 event_size의 의미를 잘 파악해야 한다. 텐서 모양에 대한 pyro 문서를 참고하고 tfp를 통하여 그 개념을 알아보겠다. . &#48176;&#52824; . 익숙한 샘플 평균의 분포에 대하여 생각해보자. 독립·동일 분포를 따르는 확률 변수 $X_k$로부터 평균에 대한 확률 변수를 $ bar X = sum_{k=1}^{n} X_k$로 기술한다. 여기서 독립적인 표본의 수 n은 확률 프로그래밍에서 batch_size를 의미한다. 하나의 표본의 차원은 event_size가 된다. tfp를 통하여 정리해 보자. . def print_sizes(rv): print(f&#39;batch_size: {rv.batch_shape}, event_shape: {rv.event_shape}&#39;) s = rv.sample() print(f&#39;sample: {s}&#39;) print(f&#39;sample size: {s.shape}, log_prob size: {rv.log_prob(s).shape}&#39;) assert rv.sample().shape == rv.batch_shape + rv.event_shape assert rv.log_prob(s).shape == rv.batch_shape return s . N(10, 2)를 따르는 모집단의 평균을 추정하기 위하여 n=6 표본을 얻어서 평균을 구했다고 하자. 다음과 같이 tfd.Normal을 설정하면 n개의 표본을 얻을 수 있다. rv의 batch_size가 6으로 설정되며 n개의 표본이 나오고, log_prob의 size도 그것에 맞게 나오는 것을 확인할 수 있다. . np.random.seed(52) n = 6 rv = tfd.Normal(loc=[10.0] * n, scale=2.0) samp = print_sizes(rv) . batch_size: (6,), event_shape: () sample: [ 9.519256 6.036186 11.836839 9.53339 12.814849 9.927071] sample size: (6,), log_prob size: (6,) . t 분포를 통하여 95% 신뢰 구간을 구하는 방법은 다음과 같다. . from scipy.stats import t m, S = np.mean(samp), np.sqrt(np.var(samp) * n / (n - 1)) m, S . (9.944598, 2.342857862432549) . (m - t.ppf(0.025, n - 1) * S / np.sqrt(n), m + t.ppf(0.025, n - 1) * S / np.sqrt(n)) . (12.403276738920084, 7.485919656953939) . &#51060;&#48292;&#53944; . 한번의 표본이 스칼라가 아닌 차원을 갖는 텐서인 경우도 있다. 다변량 정규분포가 그와 같은 경우이다. 이때의 차원은 event_size에 저장된다. . rv = tfd.MultivariateNormalDiag(loc=[1.0, -1.0], scale_diag=[1.0, 2.0]) s = print_sizes(rv) . batch_size: (), event_shape: (2,) sample: [-0.01391554 -0.6594347 ] sample size: (2,), log_prob size: () . 포본 하나를 추출하였을 때 배치 예에서 나온 샘플과 크기는 2로 같으나 이벤트 예의 샘플은 한번의 이벤트에서 나온 것이기 때문에 log_prob 크기도 그에 맞게 1개로 나온다. . samp = rv.sample((2, 3)) samp.shape, rv.log_prob(samp).shape . (TensorShape([2, 3, 2]), TensorShape([2, 3])) . &#48176;&#52824;-&#51060;&#48292;&#53944; &#51204;&#54872; . 독립적이나 동일 분포가 아닌 확률 변수를 묶어서 하나의 이벤트로 처리하는 것이 필요할 때가 있다. 이때 사용할 수 있는 객체가 tfd.Independent이다. . rv = tfd.Normal(loc=[0.0, 1.0], scale=1.0) ind = tfd.Independent( distribution=rv, reinterpreted_batch_ndims=1 ) rv.batch_shape, rv.event_shape, ind.batch_shape, ind.event_shape . (TensorShape([2]), TensorShape([]), TensorShape([]), TensorShape([2])) . rv = tfd.Normal(loc=np.random.randn(2, 3, 4), scale=1.0) ind = tfd.Independent( distribution=rv, reinterpreted_batch_ndims=2 ) rv.batch_shape, rv.event_shape, ind.batch_shape, ind.event_shape . (TensorShape([2, 3, 4]), TensorShape([]), TensorShape([2]), TensorShape([3, 4])) . &#45936;&#51060;&#53552; . 가상의 데이터에 대하여 회귀 문제를 구성해 보자. 다음 코드는 확률젹 회귀 튜토리얼에서 따온 것이며, 이 포스트 전체에서 그 튜토리얼을 따라가며 이해한 바를 정리하도록 하겠다. . w0 = 0.125 b0 = 5. x_range = [-20, 60] def load_dataset(n=150, n_tst=150): np.random.seed(43) def s(x): g = (x - x_range[0]) / (x_range[1] - x_range[0]) return 3 * (0.25 + g**2.) x = (x_range[1] - x_range[0]) * np.random.rand(n) + x_range[0] eps = np.random.randn(n) * s(x) y0 = (w0 * x * (1. + np.sin(x)) + b0) y = y0 + eps x = x[..., np.newaxis] x_tst = np.linspace(*x_range, num=n_tst).astype(np.float32) x_tst = x_tst[..., np.newaxis] return y0, y, x, x_tst y0, y, x, x_tst = load_dataset() . ax = sns.lineplot(x=x.squeeze(), y=y0) ax = sns.scatterplot(x=x.squeeze(), y=y, color=sns.color_palette()[1]) ax.set_aspect(&#39;equal&#39;); . &#47784;&#45944;4 . 확률젹 회귀 튜토리얼의 모델4을 살펴보자. tfp.layers.DenseVariational 층은 units=1+1 크기의 확률 변수가 나온다. makeposterior 함수는 kernel K와 bias B를 내 주는데 출력 확률 변수는 $Y{DV, k} = x_j K_i + B_i | X_j = xj $가 된다. 다음 층에서 $Y{DV, k=1, 2}$는 각각 정규 함수의 loc과 scale의 인수로 사용되어 새로운 확률 변수가 만들어져 관측치와 비교하게 된다. make_prior는 $K_i$와 $B_i$의 사전 분포로 충분히 넓게 설정해도 된다. . def make_prior(kernel_size, bias_size, dtype): n = kernel_size + bias_size return models.Sequential([ tfp.layers.VariableLayer(n, dtype=dtype), tfp.layers.DistributionLambda( lambda t: tfd.Independent( tfd.Normal(loc=t, scale=3.0), reinterpreted_batch_ndims=1 ) ) # batch_shape, event_shape = ([], [n]) ]) def make_posterior(kernel_size, bias_size, dtype): n = kernel_size + bias_size c = np.log(np.expm1(1.0)) return models.Sequential([ tfp.layers.VariableLayer(2 * n, dtype=dtype), tfp.layers.DistributionLambda( lambda t: tfd.Independent( tfd.Normal(loc=t[..., :n], scale=1e-5 + tf.nn.softplus(c + t[..., n:])), # softplus(c + 0) = 1 reinterpreted_batch_ndims=1 ) ) # batch_shape, event_shape = ([], [n]), X x K + b ]) . mod_4 = tf.keras.models.Sequential([ tf.keras.layers.Input(1), tfp.layers.DenseVariational(1 + 1, make_posterior, make_prior), tfp.layers.DistributionLambda( lambda t: tfd.Normal(loc=t[..., :1], scale=1e-3 + tf.math.softplus(0.01 * t[..., 1:])) ) ]) mod_4.summary() . Model: &#34;sequential&#34; _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= dense_variational (DenseVari (None, 2) 12 _________________________________________________________________ distribution_lambda (Distrib multiple 0 ================================================================= Total params: 12 Trainable params: 12 Non-trainable params: 0 _________________________________________________________________ . epochs = 1000 negloglik = lambda y, rv_y: -rv_y.log_prob(y) mod_4.compile(optimizer=tf.optimizers.Adam(learning_rate=0.01), loss=negloglik) history = mod_4.fit(x, y, epochs=epochs, verbose=False) . df = history.history df[&#39;epoch&#39;] = list(range(epochs)) df = pd.DataFrame(df) ax = sns.lineplot(data=df, x=&#39;epoch&#39;, y=&#39;loss&#39;) ax.set_yscale(&#39;log&#39;); . fig, ax = plt.subplots(figsize=(10, 5)) ax = sns.scatterplot(x=x.squeeze(), y=y, color=&#39;orange&#39;, label=&#39;observed&#39;) for i in range(15): rv_yhat = mod_4(x_tst) m = rv_yhat.mean().numpy().squeeze() s = rv_yhat.stddev().numpy().squeeze() ax = sns.lineplot(x=x_tst.squeeze(), y=m, color=&#39;r&#39;, linewidth=1.0, label=&#39;ensemble means&#39; if i == 0 else None) ax = sns.lineplot(x=x_tst.squeeze(), y=m + 2 * s, color=&#39;g&#39;, linewidth=0.5, label=&#39;ensemble means + 2 stdev&#39; if i == 0 else None) ax = sns.lineplot(x=x_tst.squeeze(), y=m - 2 * s, color=&#39;g&#39;, linewidth=0.5, label=&#39;ensemble means - 2 stdev&#39; if i == 0 else None) ax = sns.scatterplot(x=x_tst.squeeze(), y=rv_yhat.sample().numpy().squeeze(), color=&#39;b&#39;, label=&#39;sample&#39;) ax.set_aspect(&#39;equal&#39;) ax.legend(); # ax.legend([&#39;base&#39;, &#39;lm fit&#39;, &#39;train=base+noise&#39;, &#39;sample&#39;]); . 모델 4는 관측 데이터에서 놀 수 있는 확률 선형 함수를 뽑는 모델이다. 하나의 샘플에서 볼 수 있는 데이터는 여전히 관측 데이터처럼 보이지 않지만 앙상불을 거치면 추론이 가능하다. .",
            "url": "https://danhojin.github.io/jupyter-blog/ppl/2021/01/17/hello-tfp2.html",
            "relUrl": "/ppl/2021/01/17/hello-tfp2.html",
            "date": " • Jan 17, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "안녕! Tensorflow Probability - 1",
            "content": "확률 프로그래밍은 통계 추론을 목적으로 발전되었으며 확률 변수나 벡터가 도입되므로 생성 모델에도 사용된다. 대표적으로 stan, pymc3, pyro 등은 중심 라이브러리뿐만 아니라 주변 생태계가 계속 발전해 나가고 있다. 여기에 선택할 수 있는 Tensorflow Probability 라이브러리가 추가되어 개인적으로 관심을 갖게 되었다. 우선 Hello World 격인 확률적 회귀 튜토리얼을 따라가면서 여러 개념을 정리해 보겠다. . import numpy as np import pandas as pd import seaborn as sns import matplotlib.pyplot as plt %matplotlib inline import tensorflow as tf import tensorflow_probability as tfp tfd = tfp.distributions if tf.test.gpu_device_name() != &#39;/device:GPU:0&#39;: print(&#39;WARNING: GPU device not found.&#39;) else: print(&#39;SUCCESS: Found GPU: {}&#39;.format(tf.test.gpu_device_name())) . SUCCESS: Found GPU: /device:GPU:0 . &#54869;&#47456; &#48320;&#49688;: tfd . 확률 프로그래밍의 특징으로 샘플링이 가능한 확률 변수의 도입이다. Tensorflow probability에서 이를 가능하게 하는 것이 tfd 모듈이다. tfd 모듈에는 여러 확률 분포가 정의되어 있고, 그로부터 확률 변수를 생성할 수 있다. 확률 변수이므로 샘플링이 가능하고, 확률 밀도 함수 등의 여러 기본 함수에 접근할 수 있다. . rv = tfd.Normal(loc=[0.0, 2.0], scale=[1.0, 0.5]) x = np.linspace(-1.0, 3.0, 41, dtype=np.float32).reshape((-1, 1)) x = np.tile(x, (1, 2)) x = tf.convert_to_tensor(x) . pdf = rv.prob(x) pdf = pd.DataFrame({&#39;x&#39;: x[:, 0], &#39;col1&#39;: pdf[:, 0], &#39;col2&#39;: pdf[:, 1]}) pdf = pdf.melt(id_vars=&#39;x&#39;, value_vars=[&#39;col1&#39;, &#39;col2&#39;]) sns.lineplot(data=pdf, x=&#39;x&#39;, y=&#39;value&#39;, hue=&#39;variable&#39;); . s = rv.sample([100]) s = pd.DataFrame({&#39;col1&#39;: s[:, 0], &#39;col2&#39;: s[:, 1]}).reset_index() s = s.melt(id_vars=&#39;index&#39;, value_vars=[&#39;col1&#39;, &#39;col2&#39;]) sns.histplot(data=s, x=&#39;value&#39;, hue=&#39;variable&#39;, binwidth=0.5, multiple=&#39;dodge&#39;, shrink=0.8); . 분포 함수의 추론 문제라면 주어진 데이터에 대하여 나왔을 경우에 대하여 우도 함수를 계산할 수 있어야 한다. 음의 로그 우도 함수를 다음과 같이 정의하여 사용할 수 있다. . negloglik = lambda y, rv_y: -rv_y.log_prob(y) . &#45936;&#51060;&#53552; . 가상의 데이터에 대하여 회귀 문제를 구성해 보자. 다음 코드는 확률적 회귀 튜토리얼에서 따온 것이며, 이 포스트 전체에서 그 튜토리얼을 따라가며 이해한 바를 정리하도록 하겠다. . w0 = 0.125 b0 = 5. x_range = [-20, 60] def load_dataset(n=150, n_tst=150): np.random.seed(43) def s(x): g = (x - x_range[0]) / (x_range[1] - x_range[0]) return 3 * (0.25 + g**2.) x = (x_range[1] - x_range[0]) * np.random.rand(n) + x_range[0] eps = np.random.randn(n) * s(x) y0 = (w0 * x * (1. + np.sin(x)) + b0) y = y0 + eps x = x[..., np.newaxis] x_tst = np.linspace(*x_range, num=n_tst).astype(np.float32) x_tst = x_tst[..., np.newaxis] return y0, y, x, x_tst y0, y, x, x_tst = load_dataset() . ax = sns.lineplot(x=x.squeeze(), y=y0) ax = sns.scatterplot(x=x.squeeze(), y=y, color=sns.color_palette()[1]) ax.set_aspect(&#39;equal&#39;); . from tensorflow.keras import models, layers mod_1 = tf.keras.Sequential([ layers.Input(1), layers.Dense(1), tfp.layers.DistributionLambda(lambda t: tfd.Normal(loc=t, scale=1.0)), ]) mod_1.summary() . Model: &#34;sequential&#34; _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= dense (Dense) (None, 1) 2 _________________________________________________________________ distribution_lambda (Distrib multiple 0 ================================================================= Total params: 2 Trainable params: 2 Non-trainable params: 0 _________________________________________________________________ . 활성화 함수가 없으므로 첫 층은 절편과 기울기를 가진 선형 회귀로 볼 수 있다. DistributionLambda 클래스는 tfp.distributions.Distribution 인스턴스를 돌려준다. 직전 층의 출력을 확률 분포 함수의 파라미터로 삼아 확률 변수를 출력하게 된다. 한편 keras에서, 예를 들어 MSE 손실 함수는 tf.keras.losses.MSE(y_true, y_pred)로 정의되는데 첫 번째 인수가 y_true인 점에 주의하자. 앞서 정의된 negloglik(y_true, rv_y) 함수는 손실 함수로 사용할 수 있다는 점을 알 수 있다. . &#47784;&#45944;1 - &#45800;&#49692; &#49440;&#54805; &#54924;&#44480; . epochs = 500 mod_1.compile(optimizer=tf.optimizers.Adam(learning_rate=0.01), loss=negloglik) history = mod_1.fit(x, y, epochs=epochs, verbose=False) . df = history.history df[&#39;epoch&#39;] = list(range(epochs)) df = pd.DataFrame(df) ax = sns.lineplot(data=df, x=&#39;epoch&#39;, y=&#39;loss&#39;) ax.set_yscale(&#39;log&#39;); . for w in mod_1.weights: print(w) . &lt;tf.Variable &#39;dense/kernel:0&#39; shape=(1, 1) dtype=float32, numpy=array([[0.13939044]], dtype=float32)&gt; &lt;tf.Variable &#39;dense/bias:0&#39; shape=(1,) dtype=float32, numpy=array([4.9089847], dtype=float32)&gt; . 절편과 가중치는 각각 4.624, 0.146으로 계산되었다. 데이터 생성에 b0=5, w0=0.125가 사용된 것에 부합된다. 모델에서 마지막 DistributionLambda 층은 어떤 역할을 한 걸까? 확률 분포를 정의할 때 Normal(t, 1)로 scale=1로 설정한 것을 되새겨 보자. 우리의 모델은 $ sigma=1$로 대표되는 범위 내에 데이터가 많이 모이도록 회귀 적합을 수행했다는 것을 알 수 있다. 다만, 모델의 출력 결과는 확률 변수로 예측 모델링의 결정론적인 출력이 아니다. mod_1은 확률 벡터를 되돌려 주므로 샘플링을 수행할 수 있다. . rv_yhat = mod_1(x_tst) assert isinstance(rv_yhat, tfd.Distribution) . fig, ax = plt.subplots(figsize=(10, 5)) ax = sns.lineplot(x=x.squeeze(), y=y0) ax = sns.scatterplot(x=x.squeeze(), y=y, color=sns.color_palette()[1]) xlim = ax.get_xlim() xlim = np.array(xlim) abline = 4.624 + 0.146 * xlim ax = sns.lineplot(x=xlim, y=abline, color=sns.color_palette()[3], linewidth=2.0, ax=ax) ax.set_aspect(&#39;equal&#39;) ax = sns.scatterplot(x=x_tst.squeeze(), y=rv_yhat.sample(1).numpy().squeeze(), ax=ax) ax.legend([&#39;base&#39;, &#39;lm fit&#39;, &#39;train=base+noise&#39;, &#39;sample&#39;]); . mod_1은 회귀 계수의 점 추정 목적을 달성하였고 확률 벡터를 얻었지만 의미 있는 통계적인 추론을 할 수 없는 점은 분명하다. 오차 구조에 대한 어떤 모델도 들어있지 않기 때문이다. 샘플 데이터는 훈련 데이터와 상당히 다르다른 것을 그림에서 확인할 수 있다. . 이 포스트에서는 모델에 확률 변수를 쓸 수 있고, 적합 후에 샘플링을 할 수 있다는 것을 확인하였다. 그리고 확률 프로그램이 keras에 부드럽게 녹아들었다는 사실이 중요하다. 다음 포스트에서는 확률적 회귀 튜토리얼을 이어 따라가면서 tfp 확률 프로그래밍을 더 알아보도록 하겠다. .",
            "url": "https://danhojin.github.io/jupyter-blog/ppl/2021/01/16/hello-tfp1.html",
            "relUrl": "/ppl/2021/01/16/hello-tfp1.html",
            "date": " • Jan 16, 2021"
        }
        
    
  
    
        ,"post3": {
            "title": "Nadaraya-Watson 커널 회귀",
            "content": "&#50612;&#53584;&#49496; . d2l에서 Nadaraya-Watson 커널 회귀 방법을 사용하여 어텐션 개념을 소개하고 있다[1]. 어텐션을 일종의 회귀로 볼 수 있다는 점은 중요하다. 우리가 알고 있거나 이미 처리해 둔 입력과 출력으로 만들어진 함수가 존재할 때 새로운 입력에 대한 회귀 적합을 생각해 볼 수 있다. 선형 회귀 형식을 빌어보면 기울기 추정량은 다음과 같고, . $ hat beta = (X&#39;X)^{-1} (X&#39;Y)$ . 새로운 입력 $X_{ text{test}}$에 대하여 y를 추정하게 된다. . $ hat y = X_{ text{test}} hat beta = X_{ text{test}} (X&#39;X)^{-1} (X&#39;Y)$ . 위 식에는 훈련 데이터에서 특징 변수 내, 그리고 특징 변수와 응답 변수 사이의 관계가 들어 있다. 결국 새로운 입력은 훈련에 사용된 입력 및 응답을 참고하여 응답을 예측하게 된다. 일반적인 형식으로 표현하면 다음과 같고, 이를 어텐션 풀링(attention pooling)이라고 한다. . $f(x) = sum_{i=1}^{n} alpha(x, x_i) y_i $ . $ alpha$는 어텐션 계수가 되어 기지의 응답에 대한 가중치로 볼 수 있다. 이와 같이 어텐션의 개념은 간단하나 응용을 위하여, 가령 Seq2Seq 모델에 삽입해 RNN의 단점을 보완하는 어텐션 기능을 넣어야 하는 것은 또 다른 문제이므로 기존 연구자들의 성공적인 구성을 많이 참고해야 하겠다. . 일견 간단한 Nadaraya-Watson 커널 회귀 문제에 대한 d2l 코드를 처음 보았을 때 당혹감이 일었다. 수식은 간단하나 pytorch 프레임 내에서 어떻게 구현해야 하는지 머리에 떠오르지 않았기 때문이다. 이 포스트는 d2l 코드를 참고하면서 스스로 이해할 수 있도록 코드를 재구성의 결과이다. 다음 사항에 대하여 정리하는 계기가 되었다. . 학습 파라미터의 직접 정의 | torch.repeat 함수 및 텐서 연산에서 브로드캐스팅(broadcasting) | . 참고 . Aston Zhang, et al., Dive into Deep Learning, https://d2l.ai/chapter_attention-mechanisms/nadaraya-waston.html | 유원준, 딥 러닝을 이용한 자연어 처리 입문, https://wikidocs.net/22893 | # !pip install torch==1.7.1+cpu torchvision==0.8.2+cpu torchaudio==0.7.2 -f https://download.pytorch.org/whl/torch_stable.html . &#51064;&#44277; &#45936;&#51060;&#53552; &#48143; &#50976;&#54008;&#54632;&#49688; &#51221;&#51032; . d2l 코드를 그대로 재사용 하였다. . from d2l import torch as d2l import torch import torch.nn as nn import torch.nn.functional as F import numpy as np import seaborn as sns torch.manual_seed(95) n_train = 50 # No. of training examples x_train, _ = torch.sort(torch.rand(n_train) * 5) # Training inputs def f(x): return 2 * torch.sin(x) + x**0.8 y_train = f(x_train) + torch.normal(0.0, 0.5, (n_train,)) # Training outputs x_test = torch.arange(0, 5, 0.1) # Testing examples y_truth = f(x_test) # Ground-truth outputs for the testing examples print(f&#39;shape of train x/y: {x_train.shape}/{y_train.shape}&#39;) print(f&#39;shape of test x: {x_test.shape}&#39;) def plot_kernel_reg(y_hat): d2l.plot(x_test, [y_truth, y_hat], &#39;x&#39;, &#39;y&#39;, legend=[&#39;Truth&#39;, &#39;Pred&#39;], xlim=[0, 5], ylim=[-1, 5]) d2l.plt.plot(x_train, y_train, &#39;o&#39;, alpha=0.5); . shape of train x/y: torch.Size([50])/torch.Size([50]) shape of test x: torch.Size([50]) . &#50612;&#53584;&#49496; &#54400;&#47553; &#47784;&#45944; . 이미 알고 있는 데이터라는 점을 강조하기 위하여 keys/values 짝을 파라미터에 정의하였다. 이 데이터는 모델 생성시 넣어 주어야 한다. 학습 가능한 파라미터는 자유도 1인 weight 하나이다. . class NWKernelRegression(nn.Module): def __init__(self, keys, values): super().__init__() self.keys = nn.Parameter(keys, requires_grad=False) self.values = nn.Parameter(values, requires_grad=False) self.weight = nn.Parameter(torch.rand(1), requires_grad=True) @property def attention_weights(self): return self._attention_weights.detach() def forward(self, queries: torch.Tensor): N = queries.size(0) # Batch size self._attention_weights = queries - self.keys.repeat((N, 1)) self._attention_weights = F.softmax( torch.pow(self._attention_weights * self.weight, 2.0) / (-2.0), dim=-1) return (self._attention_weights * self.values.repeat((N, 1))).sum(dim=-1) # kind of torch.bmm . &#54617;&#49845; . torch.manual_seed(52) epochs, lr = 100, 0.5 mask = torch.randint(n_train, size=(int(n_train * 0.2),)) mod_1 = NWKernelRegression(x_train[~mask], y_train[~mask]) loss = nn.MSELoss(reduction=&#39;mean&#39;) optimizer = torch.optim.SGD(mod_1.parameters(), lr=lr) animator = d2l.Animator(xlabel=&#39;epoch&#39;, ylabel=&#39;loss&#39;, xlim=[0, epochs]) for epoch in range(1, epochs + 1): mod_1.train() pred = mod_1(x_train.view((-1, 1))) l = loss(pred[~mask], y_train[~mask]) optimizer.zero_grad() l.backward() optimizer.step() mod_1.eval() l_eval = loss(pred[mask], y_train[mask]) animator.add(epoch, [l.item(), l_eval.item()]) . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2021-01-15T03:54:10.902598 image/svg+xml Matplotlib v3.3.3, https://matplotlib.org/ 검증셋으로부터 epoch=30 정도부터 과적합이 되는 것을 알 수 있다. 이 값을 가지고 최종 적합을 진행하겠다. . epochs, lr = 30, 0.5 mod_1 = NWKernelRegression(x_train, y_train) loss = nn.MSELoss(reduction=&#39;mean&#39;) optimizer = torch.optim.SGD(mod_1.parameters(), lr=lr) animator = d2l.Animator(xlabel=&#39;epoch&#39;, ylabel=&#39;loss&#39;, xlim=[0, epochs]) for epoch in range(1, epochs + 1): mod_1.train() pred = mod_1(x_train.view((-1, 1))) l = loss(pred, y_train) optimizer.zero_grad() l.backward() optimizer.step() animator.add(epoch, [l.item()]) . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2021-01-15T03:54:13.472796 image/svg+xml Matplotlib v3.3.3, https://matplotlib.org/ &#54217;&#44032; . 학습 결과 weight=2.58을 얻었다. 히트맵에 때르면 검정 데이터 주변의 훈련 데이터를 참고하여 어텐션 가중치를 구하여 응답을 구성하는 것을 알 수 있다. . list([p for p in mod_1.parameters() if p.requires_grad]) . [Parameter containing: tensor([2.4232], requires_grad=True)] . mod_1.eval() y_hat = mod_1(x_test.view((-1, 1))) plot_kernel_reg(y_hat.detach()) . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2021-01-15T03:54:13.652769 image/svg+xml Matplotlib v3.3.3, https://matplotlib.org/ import seaborn as sns ax = sns.heatmap(mod_1.attention_weights.numpy(), cmap=&#39;YlGnBu&#39;) ax.set_xlabel(&#39;Sorted training inputs (keys)&#39;) ax.set_ylabel(&#39;Sorted testing inputs (queries)&#39;); . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2021-01-15T03:54:13.852701 image/svg+xml Matplotlib v3.3.3, https://matplotlib.org/",
            "url": "https://danhojin.github.io/jupyter-blog/nlp/2021/01/15/nadaraya-watson-kernel-regression.html",
            "relUrl": "/nlp/2021/01/15/nadaraya-watson-kernel-regression.html",
            "date": " • Jan 15, 2021"
        }
        
    
  
    
        ,"post4": {
            "title": "Seq2Seq 기계 번역",
            "content": "이 포스트에는 Dive into Deep Learning 9장의 Seq2Seq 코드를 재구현하였다. Seq2Seq 학습의 배경이나 자세한 내용은 d2l 누리집에 들어있으나, 직접 작성해보고 나서야 코드의 자세한 부분을 이해할 수 있었다. . Seq2Seq 학습을 통하여 해결하고자 하는 문제는 Fig. 9.7.1에 나타나 있다. 영어 문장에서 출발하여 불어로 도착하는 번역을 하고자 한다. 이 문제를 풀기 위하여 생성 모델이 가능한 오토인코더 구조로 Seq2Seq 모델을 개발하였다. 도착어 입장에서 입력과 출력은 같으며 bos(begin of sentence), eos(end of sentence) 토큰 차이만 있다. . Fig. 9.7.1 Sequence to sequence learning with an RNN encoder and an RNN decoder. . from d2l import torch as d2l import numpy as np import torch import torch.nn as nn import torch.nn.functional as F . Data . 출발과 도착어의 문장은 184, 201개의 어휘로 구성되는 작은 데이터셋이다. 문장 시작 bos, 문장 끝 eos, 채움 pad, 모름 unk 등의 특별한 의미를 갖는 단어/토큰도 이용한다. 출발·도착 문장은 뜻은 대응되나 길이가 다를 수 있고, eos 이후 seq_len를 보장하기 위하여 pad가 삽입되어 있다. valid_len에 유효 토큰의 수가 들어있다. . batch_size, seq_len = 64, 10 train_iter, src_vocab, dst_vocab = d2l.load_data_nmt(batch_size, seq_len) len(src_vocab), len(dst_vocab) . (184, 201) . &#39;|&#39;.join([src_vocab.idx_to_token[k] for k in range(10)]) . &#34;&lt;unk&gt;|&lt;pad&gt;|&lt;bos&gt;|&lt;eos&gt;|.|!|i|i&#39;m|it|go&#34; . for batch in train_iter: x, x_valid_len, y, y_valid_len = batch break x.shape, x_valid_len.shape, y.shape, y_valid_len.shape . (torch.Size([64, 10]), torch.Size([64]), torch.Size([64, 10]), torch.Size([64])) . print(f&#39;number of valid tokens: {x_valid_len[0]}&#39;) &#39; &#39;.join([src_vocab.idx_to_token[i] for i in x[0]]) . number of valid tokens: 4 . &#34;i&#39;m hit ! &lt;eos&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt;&#34; . print(f&#39;number of valid tokens: {x_valid_len[0]}&#39;) &#39; &#39;.join([dst_vocab.idx_to_token[i] for i in y[0]]) . number of valid tokens: 4 . &#39;je suis &lt;unk&gt; ! &lt;eos&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt;&#39; . Seq2Seq model . 모델의 구조 특징은 다음과 같다. . 오토인코더를 생성 모델로 사용하기 위하여 부호기 Encoder와 복호기 Decoder의 RNN 은닉 스테이트를 공유 | 은닉 스테이트의 마지막 층은 context로 칭하여 입력에 주입 | . class Seq2SeqEnc(nn.Module): def __init__(self, src_vocab_size, embed_dim, hidden_size, num_layers, dropout=0.0): super().__init__() self.embedding = nn.Embedding(src_vocab_size, embed_dim) self.rnn = nn.GRU(embed_dim, hidden_size, num_layers, dropout=dropout) def forward(self, x): x = self.embedding(x).permute(1, 0, 2) out, state = self.rnn(x) return out, state class Seq2SeqDec(nn.Module): def __init__(self, dst_vocab_size, embed_dim, hidden_size, num_layers, dropout=0.0): super().__init__() self.embedding = nn.Embedding(dst_vocab_size, embed_dim) self.rnn = nn.GRU(embed_dim + hidden_size, hidden_size, num_layers, dropout=dropout) self.linear = nn.Linear(hidden_size, dst_vocab_size) def forward(self, y, state): y = self.embedding(y).permute(1, 0, 2) context = state[-1].repeat(y.shape[0], 1, 1) # batch x hidden -&gt; seq x batch x hidden out, state = self.rnn(torch.cat([y, context], -1), state) out = self.linear(out).permute(1, 0, 2) # out.shape batch x seq x dst vocab # state.shape layers x batch x hidden return out, state class Seq2SeqEncDec(nn.Module): def __init__(self, src_vocab_size, dst_vocab_size, embed_dim, hidden_size, num_layers, dropout=0.0): super().__init__() self.enc = Seq2SeqEnc(src_vocab_size, embed_dim, hidden_size, num_layers, dropout) self.dec = Seq2SeqDec(dst_vocab_size, embed_dim, hidden_size, num_layers, dropout) def forward(self, x, y): _, state = self.enc(x) out, state = self.dec(y, state) return out, state . Loss function . 도착어의 입력 문장 머리에 bos를 삽입 | 문장마다 의미 있는 토큰 수가 다르므로 마스크 트릭을 사용 | . embed_dim, hidden_size, num_layers, dropout = 32, 32, 3, 0.1 batch_size, seq_len = 128, 10 lr, epochs, device = 0.01, 400, torch.device(&#39;cpu&#39;) # d2l.try_gpu() train_iter, src_vocab, dst_vocab = d2l.load_data_nmt(batch_size, seq_len) mod_1 = Seq2SeqEncDec(len(src_vocab), len(dst_vocab), embed_dim, hidden_size, num_layers, dropout) mod_1.to(device) optimizer = torch.optim.Adam(mod_1.parameters(), lr=lr) loss = nn.CrossEntropyLoss() animator = d2l.Animator(xlabel=&#39;epoch&#39;, ylabel=&#39;loss&#39;, xlim=[0, epochs], yscale=&#39;log&#39;) mod_1.train() for epoch in range(1, epochs + 1): losses = 0 for batch in train_iter: X, X_valid_len, Y, Y_valid_len = [x.to(device) for x in batch] bos = torch.tensor([dst_vocab[&#39;&lt;bos&gt;&#39;]] * Y.shape[0], device=device).reshape((-1, 1)) Y_in = torch.cat([bos, Y[:, :-1]], -1) Y_hat, _ = mod_1(X, Y_in) mask = torch.arange(seq_len).unsqueeze(0).to(device) &lt; Y_valid_len.unsqueeze(-1) mask = mask.reshape(-1) Y_hat = Y_hat.reshape((-1, len(dst_vocab))) Y = Y.reshape(-1) l = loss(Y_hat[mask], Y[mask]) optimizer.zero_grad() l.backward() optimizer.step() losses += l.item() animator.add(epoch, [losses]) . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2021-01-14T06:38:07.496789 image/svg+xml Matplotlib v3.3.3, https://matplotlib.org/ Prediction . 출발어 영어 입력에서 도착어 불어 생성은 ᅟpredict 함수를 이용한다. 내부절차는 다음과 같다. . 모델의 Encoder와 Decoder를 별개로 활용 | Decoder는 토큰별로 하나씩 처리하여 문장을 생성 | . def predict(model: Seq2SeqEncDec, src_sentence, src_vocab, dst_vocab, seq_len, device): model.eval() src_tokens = src_vocab[src_sentence.lower().split(&#39; &#39;)] + [src_vocab[&#39;&lt;eos&gt;&#39;]] src_valid_len = torch.tensor([min(seq_len, len(src_tokens))], device=device) src_tokens = src_tokens[:seq_len] src_tokens = src_tokens + [src_vocab[&#39;&lt;pad&gt;&#39;]] * max(0, seq_len - len(src_tokens)) src_tokens = torch.tensor(src_tokens, device=device).unsqueeze(0) # add batch dim _, state = model.enc(src_tokens) y = torch.tensor([dst_vocab[&#39;&lt;bos&gt;&#39;]], dtype=torch.long, device=device).unsqueeze(0) out = [] for _ in range(seq_len): y, state = model.dec(y, state) y = y.argmax(dim=-1) pred = y.squeeze(0).long().item() if pred == dst_vocab[&#39;&lt;eos&gt;&#39;]: break out.append(pred) return &#39; &#39;.join(dst_vocab.to_tokens(out)) . predict(mod_1, &quot;i lost .&quot;, src_vocab, dst_vocab, 10, device) . &#34;j&#39;ai perdu .&#34; . Evaluation . d2l의 코드를 거의 그대로 사용하였다. 샘플 결과만 가지고도 성능이 좋지 않은 것을 알 수 있다. 훈련 데이터가 적기도 하지만 Seq2Seq 자체만으로는 한계가 있기 때문이다. Seq2Seq 성능 개선을 위하여 어텐션 등이 개발되었으며 이에 대한 얘기는 다음으로 미루겠다. 다만 Seq2Seq 차체만으로도 RNN 이해를 위한 연습문제로 손색이 없었다. . import collections def bleu(pred_seq, label_seq, k): #@save &quot;&quot;&quot;Compute the BLEU.&quot;&quot;&quot; pred_tokens, label_tokens = pred_seq.split(&#39; &#39;), label_seq.split(&#39; &#39;) len_pred, len_label = len(pred_tokens), len(label_tokens) score = np.exp(min(0, 1 - len_label / len_pred)) for n in range(1, k + 1): num_matches, label_subs = 0, collections.defaultdict(int) for i in range(len_label - n + 1): label_subs[&#39;&#39;.join(label_tokens[i: i + n])] += 1 for i in range(len_pred - n + 1): if label_subs[&#39;&#39;.join(pred_tokens[i: i + n])] &gt; 0: num_matches += 1 label_subs[&#39;&#39;.join(pred_tokens[i: i + n])] -= 1 score *= np.power(num_matches / (len_pred - n + 1), np.power(0.5, n)) return score engs = [&#39;go .&#39;, &quot;i lost .&quot;, &#39;he &#39;s calm .&#39;, &#39;i &#39;m home .&#39;] fras = [&#39;va !&#39;, &#39;j &#39;ai perdu .&#39;, &#39;il est calme .&#39;, &#39;je suis chez moi .&#39;] for eng, fra in zip(engs, fras): translation = predict( mod_1, eng, src_vocab, dst_vocab, seq_len, device) print(f&#39;{eng} =&gt; {translation}, bleu {bleu(translation, fra, k=2):.3f}&#39;) . go . =&gt; va !, bleu 1.000 i lost . =&gt; j&#39;ai perdu ., bleu 1.000 he&#39;s calm . =&gt; bonne chance ., bleu 0.000 i&#39;m home . =&gt; je suis chez moi bon ., bleu 0.803 .",
            "url": "https://danhojin.github.io/jupyter-blog/nlp/2021/01/14/Seq2Seq.html",
            "relUrl": "/nlp/2021/01/14/Seq2Seq.html",
            "date": " • Jan 14, 2021"
        }
        
    
  
    
        ,"post5": {
            "title": "순환 신경망(RNN)을 이용한 문자열 생성",
            "content": "&#45936;&#51060;&#53552; . 낱말 3만개, 17만개의 문자열로 구성된 H. G. Well의 The Time Machine을 이용하였다. 토큰 과정이나 ngram 분석은 Dive into Deep Learning 누리집을 참고하자. 데이터는 d2l 패키지에서 불러와 바로 사용할 수 있다. . 참고 . Aston Zhang 등, Dive into deep learning, https://d2l.ai/chapter_recurrent-neural-networks/rnn-concise.html | %matplotlib inline from d2l import torch as d2l import math import torch from torch import nn from torch.nn import functional as F batch_size, seq_len = 32, 35 train_iter, vocab = d2l.load_data_time_machine(batch_size, seq_len) device = torch.device(&#39;cpu&#39;) torch.__version__ . &#39;1.7.1+cu110&#39; . 문자열은 알파벳 26자와 스페이스로 구성된다. 그 밖에 기호를 포함하여 모르는 문자는 unk에 저장되어 총 28개로 토큰화된다. . len(vocab) . 28 . &#39;, &#39;.join([vocab.idx_to_token[k] for k in range(28)]) . &#39;&lt;unk&gt;, , e, t, a, i, n, o, s, h, r, d, l, m, u, c, f, w, g, y, p, b, v, k, x, z, j, q&#39; . 훈련 데이터는 torch.long 타입으로 레이블 y는 입력 x가 한 글자씩 밀려 들어있다. 입력은 원핫 인코딩을 이용하여 변환하고 레이블은 그대로 이용하겠다. . for x, y in train_iter: break x.shape, y.shape . (torch.Size([32, 35]), torch.Size([32, 35])) . x.dtype . torch.int64 . x[0] . tensor([ 9, 2, 1, 3, 5, 13, 2, 1, 13, 4, 15, 9, 5, 6, 2, 1, 21, 19, 1, 9, 1, 18, 1, 17, 2, 12, 12, 8, 5, 3, 9, 2, 1, 3, 5]) . x0 = map(lambda idx: vocab.idx_to_token[idx], x[0]) &#39;&#39;.join(list(x0)) . &#39;he time machine by h g wellsithe ti&#39; . y0 = map(lambda idx: vocab.idx_to_token[idx], y[0]) &#39;&#39;.join(list(y0)) . &#39;e time machine by h g wellsithe tim&#39; . &#47784;&#45944; . 단방향 순환 신경층을 구성할 수 있는 Pytorch의 RNN 클래스를 이용하였다. RNN의 마지막 타임스텝 출력만이 아니라 전체 시퀀스를 이용하며 각 출력은 선형층에 연결된다. 문자열 생성이 목적으로 과적합을 막기 위한 장치는 사용하지 않았다. Pytorch의 RNN 입력은 시퀀스(L)x배치(B)x특징 차원으로 주입된다. . class SimpleRNN(nn.Module): def __init__(self, input_size, hidden_size): super().__init__() self.rnn = nn.RNN(input_size, hidden_size) # batch_first: False self.linear = nn.Linear(hidden_size, input_size) def forward(self, x): out, _ = self.rnn(x) out = F.relu(out) out = map(lambda x: F.relu(self.linear(x)), out) out = torch.stack(list(out)) return out . hidden_size = 512 input_size = vocab_size = len(vocab) mod_0 = SimpleRNN(input_size, hidden_size) mod_0.to(device) mod_0.eval() x = F.one_hot(x.T, 28).float() print(f&#39;input shape: (seq, batch, feature) {x.shape}&#39;) y_pred = mod_0(x.to(device)) y_pred.shape . input shape: (seq, batch, feature) torch.Size([35, 32, 28]) . torch.Size([35, 32, 28]) . 훈련 과정에서 lr을 크게 하면서도 수치적인 안정성을 유지하기 위하여 clip_grad_norm 함수를 사용하였다. . def train(model, train_iter, vocab, lr, num_epochs, device, use_random_iter=False): loss = nn.CrossEntropyLoss() animator = d2l.Animator(xlabel=&#39;epoch&#39;, ylabel=&#39;loss&#39;, legend=[&#39;train&#39;], xlim=[10, num_epochs]) # Initialize optimizer = torch.optim.SGD(model.parameters(), lr) # Train and predict for epoch in range(1, num_epochs + 1): l_sum = 0 for x, y in train_iter: x = F.one_hot(x.T, 28).float() y = y.T.reshape(-1) out = model(x.to(device)) l = loss(out.reshape((-1, 28)), y.to(device)) optimizer.zero_grad() l.backward() nn.utils.clip_grad_norm_(model.parameters(), 1.0) optimizer.step() l_sum += l.item() animator.add(epoch, [l_sum]) . num_epochs, lr = 500, 0.5 hidden_size = 512 input_size = vocab_size = len(vocab) mod_1 = SimpleRNN(input_size, hidden_size) mod_1.to(device) train(mod_1, train_iter, vocab, lr, num_epochs, device) . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2021-01-07T15:12:52.816955 image/svg+xml Matplotlib v3.3.3, https://matplotlib.org/ def generate(prefix, num_preds, model, vocab, device): model.eval() outputs = vocab[list(prefix)] for _ in range(num_preds): x = torch.tensor(outputs).reshape((-1, 1)) x = F.one_hot(x, 28).float() out = model(x.to(device)) out = torch.argmax(out[-1].squeeze()) outputs.append(out.item()) return &#39;&#39;.join([vocab.idx_to_token[i] for i in outputs]) out = generate(&#39;time traveller &#39;, 60, mod_1, vocab, device) out . &#39;time traveller proceeded anyreal body must have extension in four direction&#39; . &#47610;&#51004;&#47728; . 순환 신경망을 포함하는 문자열 생성 모델을 pytorch에서 구현 | map과 같은 python 함수를 사용해도 훈련이나 예측 과정에서 문제가 없음 | clip_grad_norm 함수를 사용하여 수치 불안정을 낮춤 | .",
            "url": "https://danhojin.github.io/jupyter-blog/nlp/2021/01/07/language-model-generating-characters.html",
            "relUrl": "/nlp/2021/01/07/language-model-generating-characters.html",
            "date": " • Jan 7, 2021"
        }
        
    
  
    
        ,"post6": {
            "title": "네이버 영화 리뷰의 감성 분석",
            "content": "한글로 표기된 한국어는 어형변화가 많고 조사가 많은 역할을 한다. 조사로 말미암아 어순도 유연하게 구사할 수 있을뿐만 아니라 띄어쓰기가 내용을 전달하는데 결정적인 역할을 하지도 않는다. 이런 특징은 문장의 토큰화에 어려움을 가중시킨다. 게다가 최근 한국어 문서에서 알파벳 표기가 같이 들어오는 경우도 많은데 이를 처리하는 것도 또 다른 숙제이다. 그럼에도 다른 언어를 위하여 개발된 자연어 처리를 위한 기계학습과 심층학습의 원리는 한국어에도 마찬가지로 적용할 수 있으며, 한국어 처리를 위한 원리는 보편적으로도 유용하게 쓰일 수 있을 것이다. . 이 포스트에서는 카카오에서 공개한 khaiii 형태소 분석기를 이용하여 네이버 영화 리뷰 말뭉치에 대한 감성 분석을 진행해 보겠다. . 참고 . 전창욱, 최태균, 조중현, 신성진, 텐서플로2와 머신러닝으로 시작하는 자연어 처리, 위키북스, 2020 | 프랑소와 숄레, 박해선 옮김, 케라스 창시자에게 배우는 딥러닝 | &#45936;&#51060;&#53552; . 전체 영화 리뷰 데이터에서 형태소 분석을 진행한 후 훈련셋과 검정셋으로 나누어 진행하겠다. 20만 건의 리뷰가 있으며 긍정과 부정 레이블이 들어있다. . import numpy as np import pandas as pd import matplotlib.pyplot as plt import seaborn as sns %matplotlib inline df = pd.read_csv(&#39;https://github.com/e9t/nsmc/raw/master/ratings.txt&#39;, delimiter=&#39; t&#39;) print(f&#39;The shape of dataframe: {df.shape}&#39;) df.head() . The shape of dataframe: (200000, 3) . id document label . 0 8112052 | 어릴때보고 지금다시봐도 재밌어요ㅋㅋ | 1 | . 1 8132799 | 디자인을 배우는 학생으로, 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산... | 1 | . 2 4655635 | 폴리스스토리 시리즈는 1부터 뉴까지 버릴께 하나도 없음.. 최고. | 1 | . 3 9251303 | 와.. 연기가 진짜 개쩔구나.. 지루할거라고 생각했는데 몰입해서 봤다.. 그래 이런... | 1 | . 4 10067386 | 안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화. | 1 | . fig, ax = plt.subplots(figsize=(10, 8)) median = df[&#39;document&#39;].astype(str).apply(len).median() ax = sns.histplot(df[&#39;document&#39;].astype(str).apply(len), bins=30, ax=ax); ax.axvline(x=median, linewidth=2.5, color=&#39;blue&#39;) ax.text(median - 20, -2000, f&#39;median={median}&#39;, color=&#39;blue&#39;, fontsize=15); . 리뷰 길이는 최대 140자로 제한되어 있으며 중앙값이 27로 짧은 리뷰이다. . &#54805;&#53468;&#49548; &#48516;&#49437; . 형태소 분석에 khaiii를 이용한다. 가장 간단하게 분석을 진행하기 위하여 알파벳이나 숫자, 기타 기호 등을 제거해 보면, 빈 리뷰가 생기는데 데이터 셋에서 이를 제거하였다. document_1 열에 정리된 리뷰가 저장된다. . import re p = re.compile(r&#39;^[ s]*$&#39;) df = df.dropna() df[&#39;document_1&#39;] = (df[&#39;document&#39;].copy() .map(lambda el: re.sub(r&quot;[^가-힣ㅏ-ㅣ s]&quot;, &quot; &quot;, el)) .map(lambda el: re.sub(r&#39;[ s]+&#39;, &quot; &quot;, el)) ) df[&#39;document_2&#39;] = df[&#39;document_1&#39;].copy().map( lambda el: True if p.search(el) == None else False ) df = df[df[&#39;document_2&#39;]].drop(columns=[&#39;document_2&#39;]) print(f&#39;The shape of dataframe: {df.shape}&#39;) df.head() . The shape of dataframe: (197900, 4) . id document label document_1 . 0 8112052 | 어릴때보고 지금다시봐도 재밌어요ㅋㅋ | 1 | 어릴때보고 지금다시봐도 재밌어요 | . 1 8132799 | 디자인을 배우는 학생으로, 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산... | 1 | 디자인을 배우는 학생으로 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산업... | . 2 4655635 | 폴리스스토리 시리즈는 1부터 뉴까지 버릴께 하나도 없음.. 최고. | 1 | 폴리스스토리 시리즈는 부터 뉴까지 버릴께 하나도 없음 최고 | . 3 9251303 | 와.. 연기가 진짜 개쩔구나.. 지루할거라고 생각했는데 몰입해서 봤다.. 그래 이런... | 1 | 와 연기가 진짜 개쩔구나 지루할거라고 생각했는데 몰입해서 봤다 그래 이런게 진짜 영화지 | . 4 10067386 | 안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화. | 1 | 안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화 | . 2100개의 리뷰가 제거되었다. 형태소 분석을 위한 함수를 작성하고 리뷰에 적용하여 morphemes 열에 저장하였다. . from khaiii import KhaiiiApi api = KhaiiiApi() def get_morphemes(review): morphemes = [w for w in api.analyze(review)] morphemes = [m.lex for w in morphemes for m in w.morphs] return list(morphemes) df[&#39;morphemes&#39;] = df[&#39;document_1&#39;].apply(get_morphemes) df.head() . id document label document_1 morphemes . 0 8112052 | 어릴때보고 지금다시봐도 재밌어요ㅋㅋ | 1 | 어릴때보고 지금다시봐도 재밌어요 | [어리, ㄹ, 때, 보, 고, 지금다시, 보, 아도, 재밌, 어요] | . 1 8132799 | 디자인을 배우는 학생으로, 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산... | 1 | 디자인을 배우는 학생으로 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산업... | [디자인, 을, 배우, 는, 학생, 으로, 외국, 디자이, 너, 와, 그, 들, 이... | . 2 4655635 | 폴리스스토리 시리즈는 1부터 뉴까지 버릴께 하나도 없음.. 최고. | 1 | 폴리스스토리 시리즈는 부터 뉴까지 버릴께 하나도 없음 최고 | [폴리스스토리, 시리즈, 는, 부, 터, 뉴, 까지, 버리, ㄹ께, 하나, 도, 없... | . 3 9251303 | 와.. 연기가 진짜 개쩔구나.. 지루할거라고 생각했는데 몰입해서 봤다.. 그래 이런... | 1 | 와 연기가 진짜 개쩔구나 지루할거라고 생각했는데 몰입해서 봤다 그래 이런게 진짜 영화지 | [오, 아, 연기, 가, 진, 짜, 개, 쩔, 구나, 지루, 하, ㄹ, 거, 이, ... | . 4 10067386 | 안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화. | 1 | 안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화 | [안개, 자욱, 하, ㄴ, 밤하늘, 에, 뜨, 어, 있, 는, 초승달, 같, 은, 영화] | . morphemes = [m for r in df[&#39;morphemes&#39;] for m in r] morphemes = list(morphemes) print(f&#39;The length of morphemes: {len(morphemes)}&#39;) morphemes[:5] . The length of morphemes: 3530533 . [&#39;어리&#39;, &#39;ㄹ&#39;, &#39;때&#39;, &#39;보&#39;, &#39;고&#39;] . 약 20만개의 리뷰가 350만개의 형태소로 분석되었으니, 평균적으로 각 리뷰는 형태소 18개로 구성된다. 리뷰 길이의 중앙값은 27이었으므로 상당 수의 형태소는 길이 1 또는 2인 것을 알 수 있다. 형태소에 대하여 더 분석해 보자. . from collections import Counter morphemes_freq = Counter(morphemes) morphemes_freq = list(zip(*[(k, v) for (k, v) in morphemes_freq.items()])) morphemes_freq = pd.DataFrame({&#39;morpheme&#39;: morphemes_freq[0], &#39;n&#39;: morphemes_freq[1]}) morphemes_freq = morphemes_freq.sort_values(by=&#39;n&#39;, ascending=False) morphemes_freq = morphemes_freq.reset_index(drop=True) morphemes_freq = morphemes_freq.reset_index() morphemes_freq[&#39;index&#39;] = morphemes_freq[&#39;index&#39;] + 1 morphemes_freq.head() . index morpheme n . 0 1 | 이 | 154942 | . 1 2 | 하 | 139855 | . 2 3 | ㄴ | 99839 | . 3 4 | 는 | 89213 | . 4 5 | 다 | 75460 | . morphemes_freq.morpheme[:100].values . array([&#39;이&#39;, &#39;하&#39;, &#39;ㄴ&#39;, &#39;는&#39;, &#39;다&#39;, &#39;영화&#39;, &#39;고&#39;, &#39;보&#39;, &#39;의&#39;, &#39;가&#39;, &#39;도&#39;, &#39;에&#39;, &#39;은&#39;, &#39;을&#39;, &#39;었&#39;, &#39;지&#39;, &#39;ㄹ&#39;, &#39;어&#39;, &#39;게&#39;, &#39;들&#39;, &#39;았&#39;, &#39;나&#39;, &#39;있&#39;, &#39;것&#39;, &#39;를&#39;, &#39;없&#39;, &#39;아&#39;, &#39;되&#39;, &#39;만&#39;, &#39;좋&#39;, &#39;는데&#39;, &#39;기&#39;, &#39;로&#39;, &#39;적&#39;, &#39;주&#39;, &#39;너무&#39;, &#39;였&#39;, &#39;여&#39;, &#39;으로&#39;, &#39;음&#39;, &#39;정말&#39;, &#39;네&#39;, &#39;어요&#39;, &#39;같&#39;, &#39;지만&#39;, &#39;ㄴ다&#39;, &#39;ㅁ&#39;, &#39;에서&#39;, &#39;않&#39;, &#39;안&#39;, &#39;수&#39;, &#39;말&#39;, &#39;면&#39;, &#39;아니&#39;, &#39;과&#39;, &#39;점&#39;, &#39;거&#39;, &#39;네요&#39;, &#39;시&#39;, &#39;만들&#39;, &#39;그&#39;, &#39;뭐&#39;, &#39;연기&#39;, &#39;재미있&#39;, &#39;평점&#39;, &#39;던&#39;, &#39;진짜&#39;, &#39;재밌&#39;, &#39;나오&#39;, &#39;잘&#39;, &#39;이런&#39;, &#39;겠&#39;, &#39;라&#39;, &#39;ㅠ&#39;, &#39;습니다&#39;, &#39;듯&#39;, &#39;ㅂ니다&#39;, &#39;이것&#39;, &#39;생각&#39;, &#39;싶&#39;, &#39;왜&#39;, &#39;와&#39;, &#39;최고&#39;, &#39;요&#39;, &#39;더&#39;, &#39;내&#39;, &#39;어서&#39;, &#39;스토리&#39;, &#39;아서&#39;, &#39;사람&#39;, &#39;까지&#39;, &#39;감동&#39;, &#39;오&#39;, &#39;한&#39;, &#39;보다&#39;, &#39;재미&#39;, &#39;ㅡ&#39;, &#39;배우&#39;, &#39;때&#39;, &#39;지루&#39;], dtype=object) . 영화 리뷰인 만큼 영화라는 낱말이 많이 사용되고 있어 사실상 의미가 없는 불용어로 처리해도 되겠다. 기분을 나타내는 재미는 재미, 재밌, 재미있 등의 별개의 형태소 khaiii가 분석한 것을 알 수 있다. 과도하게 많이 사용한 형태소를 찾아 보자. . # fig = px.line(morph_freq.iloc[:200], x=&#39;index&#39;, y=&#39;n&#39;, log_y=True) # fig.show() fig, ax = plt.subplots(figsize=(10, 8)) # ax.set(yscale=&#39;log&#39;) sns.lineplot(x=&#39;index&#39;, y=&#39;n&#39;, data=morphemes_freq.iloc[:200], ax=ax); . 기울기가 급격하게 변하는 15000회 이상 사용된 다음 형태소는 불용어로 지정하겠다. . stop_words = morphemes_freq.loc[morphemes_freq.n &gt; 15000, &#39;morpheme&#39;].values stop_words = set(stop_words) &#39; &#39;.join(stop_words) . &#39;의 다 하 만 를 아 어 고 보 은 있 을 좋 았 는 도 게 영화 들 가 이 었 없 나 는데 되 지 ㄴ ㄹ 에 것&#39; . morphemes_freq[&#39;morpheme&#39;].apply(len).value_counts() . 3 35970 2 32527 4 19306 5 7683 6 2387 1 2272 7 848 8 341 9 139 10 61 11 31 12 18 13 7 14 4 17 4 16 3 15 3 21 3 24 3 18 3 28 2 30 2 22 2 31 2 129 1 36 1 35 1 39 1 133 1 29 1 26 1 23 1 20 1 47 1 Name: morpheme, dtype: int64 . 대부분의 형태소는 2, 3, 4글자인 것을 알 수 있다. 100자가 넘는 형태소도 존재하는데 다음과 같은 것이며 토큰화를 거치며 제거될 것이다. . morphemes_freq[morphemes_freq[&#39;morpheme&#39;].apply(len) &gt; 100] . index morpheme n . 40688 40689 | ㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠ... | 1 | . 93706 93707 | 의리의리의리의리의리의리의리의리의리의리의리의리의리의리의리의리의리의리의리의리의리의리의리... | 1 | . 수동으로 불용어를 형태소 사전에서 제거하겠다. . morphemes = [m for m in morphemes if m not in stop_words] morphemes = [(k, v) for (v, k) in enumerate(morphemes)] morphemes = dict(morphemes) len(morphemes) . 101600 . 이렇게 얻어진 10만개의 형태소를 이용하여 감성 분석을 진행해 보자. . &#53664;&#53360;&#54868;&#50752; &#54984;&#47144;&#183;&#44160;&#51221;&#49483; &#51456;&#48708; . 우선 불용어를 제거하고, 이 과정에서 길이가 0이된 리뷰를 제거한다. . df[&#39;morphemes_2&#39;] = df[&#39;morphemes&#39;].map(lambda el: [m for m in el if m not in stop_words]) df[&#39;morphemes_2_len&#39;] = df[&#39;morphemes_2&#39;].apply(len) df = df[df[&#39;morphemes_2_len&#39;] &gt; 0] df.shape . (197640, 7) . df = (df.drop(columns=[&#39;morphemes&#39;, &#39;morphemes_2_len&#39;]) .rename(columns={&#39;morphemes_2&#39;: &#39;morphemes&#39;})) df.head() . id document label document_1 morphemes . 0 8112052 | 어릴때보고 지금다시봐도 재밌어요ㅋㅋ | 1 | 어릴때보고 지금다시봐도 재밌어요 | [어리, 때, 지금다시, 아도, 재밌, 어요] | . 1 8132799 | 디자인을 배우는 학생으로, 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산... | 1 | 디자인을 배우는 학생으로 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산업... | [디자인, 배우, 학생, 으로, 외국, 디자이, 너, 와, 그, 일, 군, 전통, ... | . 2 4655635 | 폴리스스토리 시리즈는 1부터 뉴까지 버릴께 하나도 없음.. 최고. | 1 | 폴리스스토리 시리즈는 부터 뉴까지 버릴께 하나도 없음 최고 | [폴리스스토리, 시리즈, 부, 터, 뉴, 까지, 버리, ㄹ께, 하나, 음, 최고] | . 3 9251303 | 와.. 연기가 진짜 개쩔구나.. 지루할거라고 생각했는데 몰입해서 봤다.. 그래 이런... | 1 | 와 연기가 진짜 개쩔구나 지루할거라고 생각했는데 몰입해서 봤다 그래 이런게 진짜 영화지 | [오, 연기, 진, 짜, 개, 쩔, 구나, 지루, 거, 라고, 생각, 였, 몰입, ... | . 4 10067386 | 안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화. | 1 | 안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화 | [안개, 자욱, 밤하늘, 뜨, 초승달, 같] | . fig, ax = plt.subplots(figsize=(10, 8)) sns.histplot(x=df[&#39;morphemes&#39;].apply(len), bins=30); . 리뷰의 형태소 분포는 위와 같다. 리뷰의 길이는 가변적이므로 동일한 길이의 입력으로 변환하겠다. 길이 40 이상은 절단하고 부족한 리뷰에 대해서는 패팅을 추가한다. 이를 위해서 keras의 pad_sequence 함수를 이용할 것이다. . from tensorflow.keras.preprocessing.text import Tokenizer from tensorflow.keras.preprocessing.sequence import pad_sequences . maxlen = 40 # The number of morphemes per review max_words = 80000 # 80% morphemes tokenizer = Tokenizer(num_words=max_words) tokenizer.fit_on_texts(df.morphemes) sequences = tokenizer.texts_to_sequences(df.morphemes) len(tokenizer.word_index) . 101600 . wi = [(k, v) for (k, v) in tokenizer.word_index.items()] wi = [kv for (_, kv) in zip(range(5), wi)] wi = list(wi) wi . [(&#39;기&#39;, 1), (&#39;로&#39;, 2), (&#39;적&#39;, 3), (&#39;주&#39;, 4), (&#39;너무&#39;, 5)] . data = pad_sequences(sequences, maxlen=maxlen) labels = df.label.values data.shape, labels.shape . ((197640, 40), (197640,)) . from sklearn.model_selection import train_test_split X_train, X_test, y_train, y_test = train_test_split( data, labels, test_size=0.3, random_state=952) . &#47784;&#45944; 1 . import tensorflow as tf from tensorflow.keras import models, layers embedding_dim = 100 mod_1 = models.Sequential([ layers.Embedding(max_words, embedding_dim, input_length=maxlen), layers.Flatten(), layers.Dropout(0.5), layers.Dense(32, activation=&#39;relu&#39;), layers.Dropout(0.5), layers.Dense(1, activation=&#39;sigmoid&#39;) ]) mod_1.summary() . Model: &#34;sequential&#34; _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= embedding (Embedding) (None, 40, 100) 8000000 _________________________________________________________________ flatten (Flatten) (None, 4000) 0 _________________________________________________________________ dropout (Dropout) (None, 4000) 0 _________________________________________________________________ dense (Dense) (None, 32) 128032 _________________________________________________________________ dropout_1 (Dropout) (None, 32) 0 _________________________________________________________________ dense_1 (Dense) (None, 1) 33 ================================================================= Total params: 8,128,065 Trainable params: 8,128,065 Non-trainable params: 0 _________________________________________________________________ . mod_1.compile( optimizer=&#39;rmsprop&#39;, loss=&#39;binary_crossentropy&#39;, metrics=[&#39;accuracy&#39;] ) early_stopping_cb = tf.keras.callbacks.EarlyStopping(monitor=&#39;val_accuracy&#39;, min_delta=0.0001, patience=2) history = mod_1.fit( X_train, y_train, epochs=10, batch_size=512, validation_split=0.2, callbacks=[early_stopping_cb] ) . Epoch 1/10 217/217 [==============================] - 5s 19ms/step - loss: 0.5980 - accuracy: 0.6558 - val_loss: 0.4060 - val_accuracy: 0.8125 Epoch 2/10 217/217 [==============================] - 4s 16ms/step - loss: 0.3921 - accuracy: 0.8288 - val_loss: 0.3911 - val_accuracy: 0.8215 Epoch 3/10 217/217 [==============================] - 4s 16ms/step - loss: 0.3617 - accuracy: 0.8464 - val_loss: 0.3780 - val_accuracy: 0.8319 Epoch 4/10 217/217 [==============================] - 4s 18ms/step - loss: 0.3349 - accuracy: 0.8599 - val_loss: 0.3825 - val_accuracy: 0.8312 Epoch 5/10 217/217 [==============================] - 4s 17ms/step - loss: 0.3166 - accuracy: 0.8697 - val_loss: 0.3928 - val_accuracy: 0.8286 . results = mod_1.evaluate(X_test, y_test) results . 1853/1853 [==============================] - 2s 968us/step - loss: 0.3906 - accuracy: 0.8293 . [0.3905869126319885, 0.8293361663818359] . 정확도 82.9%를 얻었다. . &#47784;&#45944; 2: &#54633;&#49457;&#44273; &#49888;&#44221;&#47581; . 전창욱 등의 자연어 처리[1]에서 모델을 가져왔다. 다만 maxlen이나 max_words는 다르게 설정하였다. . import tensorflow as tf from tensorflow.keras import models, layers from tensorflow.keras import Input from tensorflow.keras.constraints import max_norm maxlen = 40 max_words = 80000 embedding_dim = 128 inp = Input(shape=(maxlen,)) embedded_inp = layers.Embedding(max_words, embedding_dim, input_length=maxlen)(inp) embedded_inp = layers.Dropout(0.5)(embedded_inp) conv_3 = layers.Conv1D(100, 3, activation=&#39;relu&#39;, kernel_constraint=max_norm(3.0))(embedded_inp) conv_3 = layers.GlobalMaxPooling1D()(conv_3) conv_4 = layers.Conv1D(100, 4, activation=&#39;relu&#39;, kernel_constraint=max_norm(3.0))(embedded_inp) conv_4 = layers.GlobalMaxPooling1D()(conv_4) conv_5 = layers.Conv1D(100, 5, activation=&#39;relu&#39;, kernel_constraint=max_norm(3.0))(embedded_inp) conv_5 = layers.GlobalMaxPooling1D()(conv_5) out = tf.concat([conv_3, conv_4, conv_5], axis=-1) # out = layers.Dropout(0.5)(out) # out = layers.Dense(250, &quot;relu&quot;)(out) out = layers.Dense(250, &quot;relu&quot;, kernel_constraint=max_norm(3.0))(out) # out = layers.Dropout(0.5)(out) # out = layers.Dense(1, &quot;relu&quot;)(out) out = layers.Dense(1, &quot;relu&quot;, kernel_constraint=max_norm(3.0))(out) mod_2 = models.Model(inp, out) mod_2.summary() . Model: &#34;model&#34; __________________________________________________________________________________________________ Layer (type) Output Shape Param # Connected to ================================================================================================== input_1 (InputLayer) [(None, 40)] 0 __________________________________________________________________________________________________ embedding_1 (Embedding) (None, 40, 128) 10240000 input_1[0][0] __________________________________________________________________________________________________ dropout_2 (Dropout) (None, 40, 128) 0 embedding_1[0][0] __________________________________________________________________________________________________ conv1d (Conv1D) (None, 38, 100) 38500 dropout_2[0][0] __________________________________________________________________________________________________ conv1d_1 (Conv1D) (None, 37, 100) 51300 dropout_2[0][0] __________________________________________________________________________________________________ conv1d_2 (Conv1D) (None, 36, 100) 64100 dropout_2[0][0] __________________________________________________________________________________________________ global_max_pooling1d (GlobalMax (None, 100) 0 conv1d[0][0] __________________________________________________________________________________________________ global_max_pooling1d_1 (GlobalM (None, 100) 0 conv1d_1[0][0] __________________________________________________________________________________________________ global_max_pooling1d_2 (GlobalM (None, 100) 0 conv1d_2[0][0] __________________________________________________________________________________________________ tf.concat (TFOpLambda) (None, 300) 0 global_max_pooling1d[0][0] global_max_pooling1d_1[0][0] global_max_pooling1d_2[0][0] __________________________________________________________________________________________________ dense_2 (Dense) (None, 250) 75250 tf.concat[0][0] __________________________________________________________________________________________________ dense_3 (Dense) (None, 1) 251 dense_2[0][0] ================================================================================================== Total params: 10,469,401 Trainable params: 10,469,401 Non-trainable params: 0 __________________________________________________________________________________________________ . tf.keras.utils.plot_model(mod_2, show_shapes=True) . mod_2.compile( optimizer=&#39;rmsprop&#39;, loss=&#39;binary_crossentropy&#39;, metrics=[&#39;accuracy&#39;] ) early_stopping_cb = tf.keras.callbacks.EarlyStopping(monitor=&#39;val_accuracy&#39;, min_delta=0.0001, patience=2) history = mod_2.fit( X_train, y_train, epochs=10, batch_size=512, validation_split=0.2, callbacks=[early_stopping_cb] ) . Epoch 1/10 217/217 [==============================] - 10s 36ms/step - loss: 0.8143 - accuracy: 0.6626 - val_loss: 0.5413 - val_accuracy: 0.7874 Epoch 2/10 217/217 [==============================] - 8s 36ms/step - loss: 0.4931 - accuracy: 0.8087 - val_loss: 0.6397 - val_accuracy: 0.7467 Epoch 3/10 217/217 [==============================] - 8s 36ms/step - loss: 0.4788 - accuracy: 0.8198 - val_loss: 0.4737 - val_accuracy: 0.8172 Epoch 4/10 217/217 [==============================] - 8s 37ms/step - loss: 0.4582 - accuracy: 0.8346 - val_loss: 0.4968 - val_accuracy: 0.8169 Epoch 5/10 217/217 [==============================] - 8s 37ms/step - loss: 0.4499 - accuracy: 0.8460 - val_loss: 0.5240 - val_accuracy: 0.8102 . results = mod_2.evaluate(X_test, y_test) results . 1853/1853 [==============================] - 3s 2ms/step - loss: 0.5296 - accuracy: 0.8124 . [0.5295822620391846, 0.812386155128479] . 정확도 81.2%를 얻었다. . &#47610;&#51004;&#47728; . 한국어에 대한 형태소 분석, 토큰화, 이진 분류 모델을 구성 | 이를 이용하여 네이버 영화 리뷰에 대한 감성 분류 | khaiii 형태소 분석기로도 어느 정도의 성과 확인 | .",
            "url": "https://danhojin.github.io/jupyter-blog/nlp/2021/01/01/nsmc.html",
            "relUrl": "/nlp/2021/01/01/nsmc.html",
            "date": " • Jan 1, 2021"
        }
        
    
  
    
        ,"post7": {
            "title": "모분산 불편 추정량과 모 표준편차",
            "content": "수리통계학 연습 문제 4.2.10을 살피다 지금까지 별 의심 없이 써왔던 모분산의 불편 추청량 $S^2$을 다시 생각해보게 되었다. 모 표준편차의 분편 추정량을 $ sqrt{S^2}$으로 볼 수 있냐는 문제이다. 모분산의 불편 추정량은 다음과 같다. . $S^2 = frac{ sum_{i=1}^{n} (X_i - bar X_n)^2}{n - 1}$ . $X_i sim N( mu, sigma^2)$이고, $ bar X_n = sum_{i=1}^{n} X_i$이다. 불편 추청량이라 함은 $E(S^2) = sigma^2$ 식이 성립한다는 것이다. 그렇다면, $E(S) = sigma$이라고 볼 수 있나? 그렇지 않다. 더 자세한 내용은 모 표준 편차의 불편 추청에 관한 위키피디아 문서를 참고하기 바란다[2]. 문제의 힌트를 사용해서 $E(S)$를 계산해 보겠다. . $E(S) = frac{ sigma}{ sqrt{n-1}} E left[ sqrt{ frac{(n-1)S^2}{ sigma^2}} right]$ . 제곱근 안의 항은 $ frac{(n-1)S^2}{ sigma^2} sim chi^2(n-1)$이므로 감마분포의 확률밀도함수(pdf) $f(x)$를 이용하여 다음과 같이 쓸 수 있다. . $E(S) = frac{ sigma}{ sqrt{n-1}} int_0^{ infty} x^{1/2} f(x) dx$ . 단, 확률밀도함수 f(x)는 자유도 $r$과 정의 구간 $0&lt;x&lt; infty$에 대하여 다음과 같다. . $f(x) = frac{1}{ Gamma(r/2) 2^{r/2}} x^{r/2 - 1} e^{-x/2}$ . 연습문제에서 $n=9$이고, $r=n-1=8$이다. 자유도를 적분식에 넣고 감마 함수로 정리하면 어렵지 않게 $E(s)$ 값을 계산할 수도 있지만, 여기에서는 sympy 패키지를 이용하여 적분을 풀어보겠다. . 참고 문헌 . 호그, 매킨, 크레이그, 박태영 옮김, 수리통계학 개론, 7판, Pearson/경문사, 2018 | 위키피디아, Unbiased estimation of standard deviation, 최종 편집 2020년 5월 7일, https://en.wikipedia.org/wiki/Unbiased_estimation_of_standard_deviation | from sympy import * init_printing() x, sigma = symbols(&#39;x, sigma&#39;) n = 9 r = Rational(n - 1, 1) f = 1 / gamma(r / 2) / 2**(r / 2) * x**(r / 2 - 1) * exp(-x / 2) f . $ displaystyle frac{x^{3} e^{- frac{x}{2}}}{96}$ E_S = sigma / sqrt(r) * integrate(sqrt(x) * f, [x, 0, oo]) # print(E_S) E_S . $ displaystyle frac{35 sqrt{ pi} sigma}{64}$ E_S.evalf() . $ displaystyle 0.969310699713954 sigma$ 불편 분산의 제곱근 기댓값은 $E(S) = 0.969 sigma$로 불편 분산의 제곱근은 모 표준 편차의 불편량으로 사용할 수 없다는 점을 확인하였다. . 4.2.10 (b)에서 신뢰구간이 확률변수 $t(8) = sqrt{9} ( bar X - mu) / S$에 근거를 두므로 95% 신뢰 구간의 길이는 $2t_{ alpha/2, n-1} S / sqrt{n}$이다. 마지막으로 $S$와 $ sigma$ 관계를 삽입하면 신뢰 구간의 길이를 얻을 수 있다. . from scipy.stats import t import numpy as np rv = t(n - 1) 2 * rv.ppf(0.975) / np.sqrt(9) * 0.96931 . $ displaystyle 1.49015524541946$ 최종적으로 계산된 신뢰 구간의 길이는 1.49 $ sigma$이다. .",
            "url": "https://danhojin.github.io/jupyter-blog/statistics/2020/12/27/%EB%AA%A8%EB%B6%84%EC%82%B0-%EB%AA%A8%ED%91%9C%EC%A4%80%ED%8E%B8%EC%B0%A8-%EB%B6%88%ED%8E%B8-%EC%B6%94%EC%A0%95%EB%9F%89.html",
            "relUrl": "/statistics/2020/12/27/%EB%AA%A8%EB%B6%84%EC%82%B0-%EB%AA%A8%ED%91%9C%EC%A4%80%ED%8E%B8%EC%B0%A8-%EB%B6%88%ED%8E%B8-%EC%B6%94%EC%A0%95%EB%9F%89.html",
            "date": " • Dec 27, 2020"
        }
        
    
  
    
        ,"post8": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://danhojin.github.io/jupyter-blog/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post9": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://danhojin.github.io/jupyter-blog/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://danhojin.github.io/jupyter-blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://danhojin.github.io/jupyter-blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}